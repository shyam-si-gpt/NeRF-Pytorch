# NeRF with PyTorch (Blender and Custom LLFF Data Support)

This is a PyTorch implementation of **Neural Radiance Fields (NeRF)** for novel view synthesis using both Blender synthetic scenes and custom real-world data.

---

## ğŸ› ï¸ Installation

```bash
git clone <your_repo_link_here>
cd nerf-pytorch
pip install -r requirements.txt
```

**Required Libraries:**
- PyTorch 1.4+
- matplotlib
- numpy
- imageio
- imageio-ffmpeg
- configargparse
- COLMAP (for custom datasets)

---

## ğŸš€ Running NeRF

### 1. Blender Synthetic Datasets

1. Download example Blender datasets:
   ```bash
   bash download_example_data.sh
   ```

2. Train NeRF on a Blender scene like **lego**:
   ```bash
   python run_nerf.py --config configs/lego.txt
   ```

Outputs will be saved in `logs/lego_test/`.

---

### 2. Custom LLFF-style Real-world Data

#### ğŸ“· Step-by-step Pipeline

1. **Organize your images:**
   ```
   your_scene/
   â””â”€â”€ images/         # Your real-world input photos
   ```

2. **Run COLMAP**  
You can use either **GUI** or **CLI**:
- **GUI Option**:
  - Launch `colmap`
  - Run `Feature Extraction`
  - Run `Exhaustive Matching`
  - Run `Mapper` (choose `images` as input, output to `sparse`)
- **CLI Option**:
   ```bash
   colmap feature_extractor --database_path your_scene/database.db --image_path your_scene/images
   colmap exhaustive_matcher --database_path your_scene/database.db
   mkdir your_scene/sparse
   colmap mapper --database_path your_scene/database.db --image_path your_scene/images --output_path your_scene/sparse
   ```

3. **Convert COLMAP output using imgs2poses.py:**
   ```bash
   python imgs2poses.py --match_type exhaustive_matcher your_scene/
   ```

   This generates:
   ```
   your_scene/
   â”œâ”€â”€ images/
   â”œâ”€â”€ sparse/0/
   â”œâ”€â”€ poses_bounds.npy âœ…
   ```

4. **Train NeRF on your custom scene:**
   ```bash
   python run_nerf.py --config configs/fern.txt --datadir ./your_scene --dataset_type llff
   ```

5. **(Optional) Render only:**
   ```bash
   python run_nerf.py --config configs/fern.txt --render_only --datadir ./your_scene --dataset_type llff
   ```

---

## ğŸ”„ For 360-Degree Spherical Scenes

If your data is captured in a full loop (360Â°), use additional flags:

```bash
python run_nerf.py --config configs/fern.txt --datadir ./your_scene --dataset_type llff --no_ndc --spherify --lindisp
```

### Summary of Optional Flags

| Flag         | Purpose                                                                 |
|--------------|-------------------------------------------------------------------------|
| `--no_ndc`   | Disables NDC (normalized device coords), helpful for real-world data    |
| `--spherify` | Rearranges poses for spherical scenes                                   |
| `--lindisp`  | Uses linear disparity (useful for wide baseline scenes)                 |

---

## ğŸ“‚ Project Directory Structure

```
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ lego.txt (Blender dataset config)
â”‚   â”œâ”€â”€ fern.txt (LLFF-style real-world dataset config)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ nerf_synthetic/
â”‚   â”‚   â”œâ”€â”€ lego/
â”‚   â”œâ”€â”€ nerf_llff_data/
â”‚   â”‚   â”œâ”€â”€ your_custom_scene/
â”‚
â”œâ”€â”€ run_nerf.py     # Main training and rendering script
â”œâ”€â”€ imgs2poses.py   # Converts COLMAP output to poses_bounds.npy
```

---

## ğŸ§­ Summary: Custom Data Workflow

| Step | Tool / Script          | Required |
|------|------------------------|----------|
| Image Collection | Manual                  | âœ… |
| COLMAP SfM       | COLMAP GUI/CLI          | âœ… |
| Pose Conversion  | `imgs2poses.py`         | âœ… |
| Train NeRF       | `run_nerf.py`           | âœ… |

---

# ğŸ”¥ Youâ€™re now ready to train NeRF on both Blender and your own real-world data ğŸ”¥
